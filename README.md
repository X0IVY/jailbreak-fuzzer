# jailbreak-fuzzer
Automated adversarial testing framework for LLM applications - finds prompt injections, jailbreaks, and guardrail bypasses
